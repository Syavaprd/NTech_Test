{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"from os import listdir\nfrom os.path import join, dirname, abspath, isfile\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import BatchNormalization, Flatten\nfrom keras.optimizers import SGD, Adam\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping, LearningRateScheduler, ModelCheckpoint\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.regularizers import l2\nimport numpy as np\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\nimport tensorflow\nimport glob\nfrom keras.models import load_model\nimage_size = 260\n\ndef train_classifier(img_dir, epochs, batch_size, num_classes = 2, fast_train=False):                                                 # train_function\n    print(\"training\")\n    \n    # model definition\n    base_model = tensorflow.keras.applications.EfficientNetB2(weights='imagenet', include_top=False, input_shape=(image_size,image_size,3), classes=2)\n    base_model.trainable = True\n    model = Sequential()\n    model.add(base_model)\n    model.add(GlobalAveragePooling2D())\n    #model.add(Flatten())\n    #model.add(BatchNormalization())\n    #model.add(Dense(256, activation='relu'))\n    #model.add(Dropout(0.4))\n    \n    model.add(BatchNormalization())\n    model.add(Dense(128, activation='relu'))\n    #model.add(Dropout(0.4))\n    \n    model.add(Dense(1, activation='sigmoid', kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01)))\n    \n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.001), metrics=[\"accuracy\"])\n    model.summary()                                                 \n    \n    # you can set fast_train to true, to check the train function\n    if fast_train:\n        epochs=1\n        batch_size=1\n    callbacks = [\n        ReduceLROnPlateau(factor=0.4, patience=3, min_lr=0.000001, verbose=1),\n        ModelCheckpoint('final_model.hdf5', verbose=1, save_best_only=True, monitor='val_accuracy', mode='max')\n    ]\n    \n    # datagenerator definition\n    train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        rotation_range=30,\n        zoom_range=0.1,\n        horizontal_flip=True,\n        validation_split=0.2)\n\n    train_generator = train_datagen.flow_from_directory(\n        img_dir,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='training') # set as training data\n\n    validation_generator = train_datagen.flow_from_directory(\n        img_dir,\n        target_size=(image_size, image_size),\n        batch_size=batch_size,\n        class_mode='binary',\n        subset='validation') # set as validation data\n    \n    # fit model\n    model.fit_generator(\n        train_generator,\n        steps_per_epoch = 128,\n        validation_data = validation_generator, \n        validation_steps = 64,\n        epochs = epochs, callbacks=callbacks)\n    \n    return model\n\ndef classify(path_to_model, test_img_dir):\n    x=[]\n    result = {}\n    model = load_model(path_to_model)\n    cnt = 0\n    onlyfiles = [f for f in listdir(test_img_dir) if isfile(join(test_img_dir, f))]\n    for fname in onlyfiles:\n        img = image.load_img(join(test_img_dir,fname), target_size=(image_size, image_size))\n        img = image.img_to_array(img)\n        img = preprocess_input(img)\n        img = np.expand_dims(img, 0)\n        cnt += 1\n        y_prob = model.predict(img, batch_size=1)\n        if y_prob[0][0] >= 0.5:\n            result[fname] = 'male'\n        else:\n            result[fname] = 'female'\n        if cnt == 213:\n            break\n    \n    with open('./process_results.json', 'w') as fp:\n        json.dump(result, fp)\n","execution_count":94,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_classifier('../input/male-female-final/to_download', 15, 64)","execution_count":2,"outputs":[{"output_type":"stream","text":"training\nDownloading data from https://storage.googleapis.com/keras-applications/efficientnetb2_notop.h5\n31793152/31790344 [==============================] - 0s 0us/step\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nefficientnetb2 (Functional)  (None, 9, 9, 1408)        7768569   \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 1408)              0         \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 1408)              5632      \n_________________________________________________________________\ndense (Dense)                (None, 128)               180352    \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 129       \n=================================================================\nTotal params: 7,954,682\nTrainable params: 7,884,291\nNon-trainable params: 70,391\n_________________________________________________________________\nFound 80002 images belonging to 2 classes.\nFound 20000 images belonging to 2 classes.\nEpoch 1/15\n128/128 [==============================] - ETA: 0s - loss: 0.2533 - accuracy: 0.9047\nEpoch 00001: val_accuracy improved from -inf to 0.94434, saving model to final_model.hdf5\n128/128 [==============================] - 266s 2s/step - loss: 0.2533 - accuracy: 0.9047 - val_loss: 0.1649 - val_accuracy: 0.9443\nEpoch 2/15\n128/128 [==============================] - ETA: 0s - loss: 0.1317 - accuracy: 0.9558\nEpoch 00002: val_accuracy improved from 0.94434 to 0.96729, saving model to final_model.hdf5\n128/128 [==============================] - 261s 2s/step - loss: 0.1317 - accuracy: 0.9558 - val_loss: 0.0961 - val_accuracy: 0.9673\nEpoch 3/15\n128/128 [==============================] - ETA: 0s - loss: 0.1098 - accuracy: 0.9612\nEpoch 00003: val_accuracy improved from 0.96729 to 0.96899, saving model to final_model.hdf5\n128/128 [==============================] - 264s 2s/step - loss: 0.1098 - accuracy: 0.9612 - val_loss: 0.1019 - val_accuracy: 0.9690\nEpoch 4/15\n128/128 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9661\nEpoch 00004: val_accuracy did not improve from 0.96899\n128/128 [==============================] - 259s 2s/step - loss: 0.1032 - accuracy: 0.9661 - val_loss: 0.1128 - val_accuracy: 0.9585\nEpoch 5/15\n128/128 [==============================] - ETA: 0s - loss: 0.0864 - accuracy: 0.9706\nEpoch 00005: val_accuracy did not improve from 0.96899\n128/128 [==============================] - 261s 2s/step - loss: 0.0864 - accuracy: 0.9706 - val_loss: 0.0918 - val_accuracy: 0.9685\nEpoch 6/15\n128/128 [==============================] - ETA: 0s - loss: 0.0896 - accuracy: 0.9674\nEpoch 00006: val_accuracy improved from 0.96899 to 0.97168, saving model to final_model.hdf5\n128/128 [==============================] - 261s 2s/step - loss: 0.0896 - accuracy: 0.9674 - val_loss: 0.0898 - val_accuracy: 0.9717\nEpoch 7/15\n128/128 [==============================] - ETA: 0s - loss: 0.0749 - accuracy: 0.9727\nEpoch 00007: val_accuracy did not improve from 0.97168\n128/128 [==============================] - 259s 2s/step - loss: 0.0749 - accuracy: 0.9727 - val_loss: 0.0920 - val_accuracy: 0.9700\nEpoch 8/15\n128/128 [==============================] - ETA: 0s - loss: 0.0923 - accuracy: 0.9680\nEpoch 00008: val_accuracy improved from 0.97168 to 0.97241, saving model to final_model.hdf5\n128/128 [==============================] - 261s 2s/step - loss: 0.0923 - accuracy: 0.9680 - val_loss: 0.0832 - val_accuracy: 0.9724\nEpoch 9/15\n128/128 [==============================] - ETA: 0s - loss: 0.0784 - accuracy: 0.9722\nEpoch 00009: val_accuracy did not improve from 0.97241\n128/128 [==============================] - 258s 2s/step - loss: 0.0784 - accuracy: 0.9722 - val_loss: 0.0940 - val_accuracy: 0.9658\nEpoch 10/15\n128/128 [==============================] - ETA: 0s - loss: 0.0733 - accuracy: 0.9713\nEpoch 00010: val_accuracy did not improve from 0.97241\n128/128 [==============================] - 252s 2s/step - loss: 0.0733 - accuracy: 0.9713 - val_loss: 0.0903 - val_accuracy: 0.9653\nEpoch 11/15\n128/128 [==============================] - ETA: 0s - loss: 0.0723 - accuracy: 0.9734\nEpoch 00011: val_accuracy improved from 0.97241 to 0.97266, saving model to final_model.hdf5\n128/128 [==============================] - 251s 2s/step - loss: 0.0723 - accuracy: 0.9734 - val_loss: 0.0818 - val_accuracy: 0.9727\nEpoch 12/15\n128/128 [==============================] - ETA: 0s - loss: 0.0745 - accuracy: 0.9728\nEpoch 00012: val_accuracy improved from 0.97266 to 0.98120, saving model to final_model.hdf5\n128/128 [==============================] - 252s 2s/step - loss: 0.0745 - accuracy: 0.9728 - val_loss: 0.0625 - val_accuracy: 0.9812\nEpoch 13/15\n128/128 [==============================] - ETA: 0s - loss: 0.0628 - accuracy: 0.9777\nEpoch 00013: val_accuracy did not improve from 0.98120\n128/128 [==============================] - 252s 2s/step - loss: 0.0628 - accuracy: 0.9777 - val_loss: 0.0614 - val_accuracy: 0.9773\nEpoch 14/15\n128/128 [==============================] - ETA: 0s - loss: 0.0712 - accuracy: 0.9741\nEpoch 00014: val_accuracy did not improve from 0.98120\n128/128 [==============================] - 255s 2s/step - loss: 0.0712 - accuracy: 0.9741 - val_loss: 0.1240 - val_accuracy: 0.9553\nEpoch 15/15\n128/128 [==============================] - ETA: 0s - loss: 0.0684 - accuracy: 0.9762\nEpoch 00015: val_accuracy did not improve from 0.98120\n128/128 [==============================] - 254s 2s/step - loss: 0.0684 - accuracy: 0.9762 - val_loss: 0.0735 - val_accuracy: 0.9719\n","name":"stdout"},{"output_type":"execute_result","execution_count":2,"data":{"text/plain":"<tensorflow.python.keras.engine.sequential.Sequential at 0x7f3ffb181d90>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"classify('./final_model.hdf5', '../input/male-female-final/to_download/female')","execution_count":95,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"with open('./process_results.json', 'r') as fp:\n    data = json.load(fp)","execution_count":96,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(data)","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"213"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"data","execution_count":98,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"unhashable type: 'slice'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-98-9617292eb96a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mTypeError\u001b[0m: unhashable type: 'slice'"]}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}